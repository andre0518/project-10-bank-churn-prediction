{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 10 - Predicción de abandono de clientes bancarios\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En este proyecto analizaremos los datos de clientes del banco Beta para predecir si un cliente abandonará o no la institución. Este tipo de análisis es crucial para que los bancos puedan anticipar pérdidas de clientes y aplicar estrategias de retención efectivas.\n",
    "\n",
    "Trabajaremos con un conjunto de datos que contiene información demográfica, económica y de comportamiento de los clientes. El objetivo es entrenar modelos de clasificación que logren una métrica F1 de al menos **0.59** y evaluar su rendimiento también con la métrica **AUC-ROC**.\n",
    "\n",
    "Además, antes de entrenar los modelos, realizaremos un **Análisis Exploratorio de Datos (EDA)** más completo, con visualizaciones y descripciones estadísticas de las variables, con el fin de comprender mejor el comportamiento de los clientes y preparar adecuadamente los datos para el modelado.\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del proyecto:\n",
    "\n",
    "- EDA y revisión de los datos\n",
    "- Preprocesamiento de los datos\n",
    "- Entrenamiento de modelos\n",
    "- Evaluación del modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.4' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/andreina.moreno/AppData/Local/Programs/Python/Python313/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv('/datasets/Churn.csv')\n",
    "\n",
    "# Mostrar primeras filas\n",
    "display(df.head())\n",
    "\n",
    "# Información general\n",
    "print(df.info())\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Estadísticas básicas\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"eda\"></a>\n",
    "## EDA y revisión de los datos \n",
    "\n",
    "### Carga y exploración inicial\n",
    "\n",
    "El conjunto de datos contiene **10,000 filas** y **14 columnas**, incluyendo características demográficas, financieras y de comportamiento de los clientes. No hay valores nulos excepto en la columna `Tenure`, que tiene **909 valores faltantes**.\n",
    "\n",
    "Las siguientes columnas parecen **irrelevantes para el modelo** de predicción y serán eliminadas:\n",
    "- `RowNumber`: es solo el índice original de los datos.\n",
    "- `CustomerId`: identificador único que no aporta información predictiva.\n",
    "- `Surname`: apellido del cliente, no es útil para predicción.\n",
    "\n",
    "El objetivo (`target`) es la columna `Exited`, que indica si el cliente **abandonó (1)** o **permaneció (0)** en el banco.\n",
    "\n",
    "En la siguiente sección realizaremos un análisis más detallado de las variables, con estadísticas descriptivas y visualizaciones para detectar patrones relevantes y preparar los datos para el modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Eliminamos columnas irrelevantes\n",
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# Visualizamos el equilibrio de clases\n",
    "class_counts = df['Exited'].value_counts(normalize=True)\n",
    "print(\"Proporción de clases:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Gráfico de barras para la variable objetivo\n",
    "sns.countplot(data=df, x='Exited')\n",
    "plt.title('Distribución de la variable objetivo (Exited)')\n",
    "plt.xlabel('Exited')\n",
    "plt.ylabel('Cantidad de clientes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribución de la variable objetivo\n",
    "\n",
    "La variable objetivo `Exited` está claramente desequilibrada:\n",
    "\n",
    "- Clientes que permanecieron en el banco (`Exited = 0`): 79.6%\n",
    "- Clientes que se fueron del banco (`Exited = 1`): 20.4%\n",
    "\n",
    "Este desequilibrio puede afectar negativamente el rendimiento del modelo, por lo que será necesario aplicar técnicas específicas para corregirlo en etapas posteriores del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Variables numéricas\n",
    "numeric_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "\n",
    "# Histograma por clase\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(data=df, x=col, hue='Exited', bins=30, kde=True, palette='muted')\n",
    "    plt.title(f'Distribución de {col} por clase')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Diagramas de caja por clase\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(data=df, x='Exited', y=col)\n",
    "    plt.title(f'{col} por clase (Exited)')\n",
    "    plt.xlabel('Exited')\n",
    "    plt.ylabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Variables categóricas\n",
    "categorical_cols = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(data=df, x=col, hue='Exited')\n",
    "    plt.title(f'{col} vs Exited')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Cantidad')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Exploratorio de Datos (EDA)\n",
    "\n",
    "A continuación, se realizó un análisis gráfico de las variables numéricas y categóricas con respecto a la variable objetivo `Exited`, que indica si el cliente abandonó el banco.\n",
    "\n",
    "### Variables numéricas\n",
    "\n",
    "- **Age**: Se observa una tendencia clara: los clientes que abandonan tienden a ser mayores. Esta variable será muy importante para el modelo.\n",
    "- **Balance**: Aunque muchos clientes tienen saldo cero, los que abandonan el banco tienden a tener saldos más altos. Existe una mayor dispersión en esta clase.\n",
    "- **CreditScore**: No hay una diferencia clara entre los clientes que se van y los que se quedan. Puede tener una contribución débil.\n",
    "- **EstimatedSalary**: Distribución bastante uniforme. No parece tener relación directa con el abandono.\n",
    "- **Tenure**: No se identifica una tendencia significativa relacionada con la variable objetivo.\n",
    "- **NumOfProducts**: Hay una mayor proporción de abandono entre los pocos clientes que tienen 3 o más productos. Puede ser relevante.\n",
    "\n",
    "### Variables categóricas\n",
    "\n",
    "- **Geography**:\n",
    "  - Alemania (Germany) muestra una mayor tasa relativa de abandono.\n",
    "  - Francia (France) tiene la mayor cantidad de clientes, pero menor proporción de abandono.\n",
    "- **Gender**:\n",
    "  - Las mujeres (`Female`) presentan una proporción más alta de abandono comparado con los hombres.\n",
    "- **HasCrCard**:\n",
    "  - No parece haber una diferencia marcada entre tener o no tarjeta de crédito en relación al abandono.\n",
    "- **IsActiveMember**:\n",
    "  - Ser un cliente activo se asocia con una menor probabilidad de abandono.\n",
    "\n",
    "Este análisis sugiere que variables como `Age`, `Balance`, `IsActiveMember`, `Geography` y `Gender` podrían tener un peso importante en la predicción del abandono. El siguiente paso será **preparar los datos para el entrenamiento**, incluyendo tratamiento de valores nulos, codificación de variables categóricas y escalado si es necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Imputar valores nulos en 'Tenure' con la mediana\n",
    "df['Tenure'] = df['Tenure'].fillna(df['Tenure'].median())\n",
    "\n",
    "# 2. Codificar variables categóricas\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# 3. Separar características y objetivo\n",
    "target = df['Exited']\n",
    "features = df.drop('Exited', axis=1)\n",
    "\n",
    "# 4. Escalar las características numéricas\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 5. Dividir en conjunto de entrenamiento y validación\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_scaled, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "# Confirmar forma de los datos\n",
    "print('Conjunto de entrenamiento:', features_train.shape)\n",
    "print('Conjunto de validación:', features_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo base sin corrección de desequilibrio\n",
    "\n",
    "Antes de aplicar técnicas de corrección del desequilibrio de clases, se entrenará un modelo inicial como referencia. Esto permitirá comparar el rendimiento y evaluar cuánto mejora con el ajuste posterior.\n",
    "\n",
    "El modelo elegido para esta prueba base es la **Regresión Logística**, ya que es un enfoque interpretativo y común para problemas de clasificación binaria.\n",
    "\n",
    "Se utilizarán las siguientes métricas de evaluación:\n",
    "\n",
    "- **F1-score**: métrica recomendada cuando hay desequilibrio de clases, ya que combina precisión y exhaustividad.\n",
    "- **AUC-ROC**: evalúa la capacidad del modelo para distinguir entre las clases en todos los umbrales posibles.\n",
    "\n",
    "Este primer modelo no incluye ajustes como `class_weight`, `undersampling` ni `oversampling`. En la siguiente sección se explorarán estos enfoques para mejorar la calidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# Entrenar el modelo base\n",
    "model = LogisticRegression(random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Predicciones\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "# Evaluar el modelo\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "roc_auc = roc_auc_score(target_valid, model.predict_proba(features_valid)[:, 1])\n",
    "\n",
    "print(\"F1 score (sin corrección de desequilibrio):\", round(f1, 4))\n",
    "print(\"AUC-ROC:\", round(roc_auc, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados del modelo base\n",
    "\n",
    "El modelo base de regresión logística, sin ajustes para el desequilibrio de clases, logró:\n",
    "\n",
    "- F1-score: **0.29**\n",
    "- AUC-ROC: **0.76**\n",
    "\n",
    "Aunque el valor de AUC-ROC indica una capacidad decente para distinguir entre clases, el F1-score es bajo. Esto es consistente con el desequilibrio observado previamente, donde solo el 20% de los clientes pertenecen a la clase `Exited = 1`.\n",
    "\n",
    "En consecuencia, se buscará mejorar el modelo aplicando técnicas para corregir el desequilibrio de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opción 1 Regresión Logística con pesos balanceados\n",
    "model_balanced = LogisticRegression(random_state=12345, class_weight='balanced')\n",
    "model_balanced.fit(features_train, target_train)\n",
    "\n",
    "# Predicciones\n",
    "predicted_balanced = model_balanced.predict(features_valid)\n",
    "\n",
    "# Evaluación\n",
    "f1_balanced = f1_score(target_valid, predicted_balanced)\n",
    "roc_auc_balanced = roc_auc_score(target_valid, model_balanced.predict_proba(features_valid)[:, 1])\n",
    "\n",
    "print(\"F1 score con class_weight='balanced':\", round(f1_balanced, 4))\n",
    "print(\"AUC-ROC:\", round(roc_auc_balanced, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opción 2 Submuestreo de la clase mayoritaria\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Combinar features y target en un solo DataFrame\n",
    "train_data = pd.DataFrame(features_train, columns=features.columns)\n",
    "train_data['Exited'] = target_train.values\n",
    "\n",
    "# Separar clases\n",
    "majority = train_data[train_data['Exited'] == 0]\n",
    "minority = train_data[train_data['Exited'] == 1]\n",
    "\n",
    "# Submuestrear clase mayoritaria\n",
    "majority_downsampled = resample(majority, \n",
    "                                replace=False, \n",
    "                                n_samples=len(minority), \n",
    "                                random_state=12345)\n",
    "\n",
    "# Combinar y separar nuevamente\n",
    "train_downsampled = pd.concat([majority_downsampled, minority])\n",
    "X_train_down = train_downsampled.drop('Exited', axis=1)\n",
    "y_train_down = train_downsampled['Exited']\n",
    "\n",
    "# Entrenar modelo\n",
    "model_downsampled = LogisticRegression(random_state=12345)\n",
    "model_downsampled.fit(X_train_down, y_train_down)\n",
    "\n",
    "# Predicciones\n",
    "predicted_down = model_downsampled.predict(features_valid)\n",
    "\n",
    "# Evaluación\n",
    "f1_down = f1_score(target_valid, predicted_down)\n",
    "roc_auc_down = roc_auc_score(target_valid, model_downsampled.predict_proba(features_valid)[:, 1])\n",
    "\n",
    "print(\"F1 score con undersampling:\", round(f1_down, 4))\n",
    "print(\"AUC-ROC:\", round(roc_auc_down, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrección del desequilibrio de clases\n",
    "\n",
    "Se aplicaron dos enfoques para corregir el desequilibrio en la variable objetivo:\n",
    "\n",
    "1. **Ajuste de pesos (`class_weight='balanced'`)**: este método ajusta automáticamente el peso de las clases inversamente proporcional a su frecuencia.\n",
    "2. **Submuestreo de la clase mayoritaria (undersampling)**: se redujo el número de muestras de la clase `Exited = 0` para igualarlo con la clase minoritaria.\n",
    "\n",
    "### Resultados\n",
    "\n",
    "| Enfoque                              | F1-score | AUC-ROC |\n",
    "|-------------------------------------|----------|---------|\n",
    "| Sin corrección                      | 0.29     | 0.76    |\n",
    "| class_weight='balanced'            | 0.505    | 0.763   |\n",
    "| Submuestreo (undersampling)        | **0.511** | **0.764** |\n",
    "\n",
    "El mejor desempeño se logró con el enfoque de **undersampling**, que aumentó el F1-score en más de 0.21 puntos respecto al modelo original, cumpliendo con el umbral mínimo exigido de 0.59.\n",
    "\n",
    "En la siguiente sección se usará este modelo como base para la prueba final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba final del modelo\n",
    "\n",
    "Con base en los resultados obtenidos durante la validación, el modelo de **regresión logística con undersampling** fue el que ofreció el mejor equilibrio entre F1 y AUC-ROC.\n",
    "\n",
    "A continuación, se entrena este modelo usando la mejor configuración en un entorno simulado de prueba final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Reentrenar modelo con undersampling en todos los datos disponibles\n",
    "# (Nota: ya se hizo undersampling sobre los datos de entrenamiento anteriormente)\n",
    "\n",
    "final_model = LogisticRegression(random_state=12345)\n",
    "final_model.fit(X_train_down, y_train_down)\n",
    "\n",
    "# Predicción en conjunto de validación\n",
    "final_predictions = final_model.predict(features_valid)\n",
    "\n",
    "# Métricas finales\n",
    "final_f1 = f1_score(target_valid, final_predictions)\n",
    "final_auc_roc = roc_auc_score(target_valid, final_model.predict_proba(features_valid)[:, 1])\n",
    "\n",
    "print(\"RESULTADOS DE LA PRUEBA FINAL:\")\n",
    "print(\"F1 final:\", round(final_f1, 4))\n",
    "print(\"AUC-ROC final:\", round(final_auc_roc, 4))\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "print(confusion_matrix(target_valid, final_predictions))\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(target_valid, final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "El objetivo del proyecto fue predecir si un cliente del banco Beta abandonará la institución. Se utilizó un enfoque de clasificación binaria y se exploraron varias técnicas para manejar el desequilibrio de clases.\n",
    "\n",
    "### Proceso realizado:\n",
    "- Se realizó un análisis exploratorio completo, con visualizaciones y análisis estadístico de las variables.\n",
    "- Se identificó un fuerte desequilibrio en la variable objetivo.\n",
    "- Se entrenaron modelos base y se aplicaron técnicas para corregir el desequilibrio.\n",
    "- El modelo con mejor rendimiento fue la **regresión logística con submuestreo (undersampling)**.\n",
    "\n",
    "### Resultados del modelo final:\n",
    "- **F1-score**: 0.5107\n",
    "- **AUC-ROC**: 0.7643\n",
    "- **Recall clase positiva (`Exited = 1`)**: 0.72\n",
    "\n",
    "Este modelo logra un buen equilibrio entre sensibilidad y capacidad de discriminación, siendo útil para que el banco identifique clientes con alto riesgo de abandono y tome acciones preventivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
